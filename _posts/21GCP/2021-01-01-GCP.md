---
title: GCP - Google Cloud Platform Fundamentals - Core Infrastructure 
date: 2021-01-01 11:11:11 -0400
categories: [21GCP]
tags: [GCP]
toc: true
image:
---

[toc]

---


# GCP

---

## GCP Fundamentals


GCP offers four main kinds of services: compute, storage, big data and machine learning.

Could Computing

![Screen](https://i.imgur.com/7vMDIFw.png)

![Screen Shot 2021-02-03 at 14.32.13](https://i.imgur.com/6p8blb8.png)

![Screen Shot 2021-02-03 at 14.34.02](https://i.imgur.com/e2nAsAC.png)

---

### GCP regions and zones

![Screen Shot 2021-02-03 at 14.52.03](https://i.imgur.com/mIV2CbL.png)


### Google offers customer-friendly pricing

![Screen Shot 2021-02-03 at 14.54.20](https://i.imgur.com/09yBI1V.png)




### Open APIs

![Screen Shot 2021-02-03 at 14.55.17](https://i.imgur.com/1b92Wl8.png)



![Screen Shot 2021-02-03 at 15.07.14](https://i.imgur.com/UEaBU7M.png)

---


### The Google Cloud Platform resource hierarchy

![Screen Shot 2021-02-03 at 15.08.50](https://i.imgur.com/vyjFXrm.png)


![Screen Shot 2021-02-03 at 15.10.01](https://i.imgur.com/demzTIm.png)


![Screen Shot 2021-02-03 at 15.09.24](https://i.imgur.com/pHBr2vk.png)


![Screen Shot 2021-02-03 at 15.11.03](https://i.imgur.com/ucg52Zc.png)



---

## Identity and Access Management (IAM)

![Screen Shot 2021-02-03 at 15.24.58](https://i.imgur.com/NRpqXEe.png)

![Screen Shot 2021-02-03 at 15.25.25](https://i.imgur.com/t4zsqr4.png)

![Screen Shot 2021-02-03 at 15.25.44](https://i.imgur.com/3pIlSRt.png)

![Screen Shot 2021-02-03 at 15.26.00](https://i.imgur.com/zwmpguY.png)

![Screen Shot 2021-02-03 at 15.28.19](https://i.imgur.com/V6W9P6y.png)

![Screen Shot 2021-02-03 at 15.28.34](https://i.imgur.com/QfUz8Ig.png)



---


### Interacting with Google Cloud Platform


![Screen Shot 2021-02-03 at 15.29.56](https://i.imgur.com/VPu8vIk.png)







---

## Cloud Marketplace (formerly Cloud Launcher)



---

## VPC Virtual Private Cloud

### Virtual Private Cloud

- define the own VPC inside the GCP project, or choose the default VPC and get started with that.

- VPC networks connect the Google Cloud platform resources to each other and to the internet.
  - segment the networks,
  - use firewall rules to restrict access to instances,
  - and create static routes to forward traffic to specific destinations.

- The Virtual Private Cloud networks have global scope.
  - can have subnets in any GCP region worldwide
  - subnets can span the zones that make up a region.
- benifit:
  - define the own network layout with global scope.
  - can have resources in different zones on the same subnet.
  - can dynamically increase the size of a subnet in a custom network by expanding the range of IP addresses allocated to it.
  - Doing that doesn't affect already configured VMs.

- VPC subnets have regional scope.
  - subnet can span the zones that make up a region.
  - solutions can incorporate fault tolerance without complicating the network topology.

example
- the VPC has one network.
- it has one subnet defined in GCP us-east1 region.
- it has two Compute Engine VMs attached to it.
- They're neighbors on the same subnet even though they are in different zones.
- solutions that are resilient but still have simple network layouts.

![Screen Shot 2021-02-03 at 15.48.15](https://i.imgur.com/xVdAWp7.png)

---

### routing tables
- Much like physical networks, VPCs have routing tables.
- used to forward traffic from one instance to another instance within the same network.
- Even across sub-networks and even between GCP zones without requiring an external IP address.
- VPCs routing tables are built in,
  - don't have to provision or manage a router.
  - don't have to provision or manage for GCP, a firewall instance.

---

### global distributed firewall.
- control to restrict access to instances, both incoming and outgoing traffic.
- define firewall rules in terms of metadata tags on Compute Engine instances
- example
- tag all the web servers with say, "web,"
- and write a firewall rule saying that traffic on ports 80 or 443 is allowed into all VMs with the "web" tag, no matter what their IP address happens to be.


---

### VPC connection

> VPCs belong to GCP projects
> if the company has several GCP projects and the VPCs need to talk to each other

VPC Peering
- peering relationship between two VPCs to exchange traffic  
- to interconnect networks in GCP projects

Shared VPC
- to share a network, or individual subnets, with other GCP projects
- to use the full power of IAM
- to control who and what in one project can interact with a VPC in another


---


### Cloud Load Balancing
- a fully distributed, software-defined managed service for all the traffic.
- because the load balancers don't run in VMs, no worry about scaling or managing them.
- put Cloud Load Balancing in front of all the traffic
  - HTTP and HTTPS, TCP and SSL traffic, and UDP traffic too.

- Cloud Load Balancing
  - basic
    - you application presents a single front-end to the world
    - users get a single, global anycast IP address
    - Traffic goes over the google backbone from the closet point-of-presence to the user
      - backend instances in regions around the world.
  - provides <font color=red> cross-region load balancing </font>
    - including automatic multi-region failover,
  - backbone are selected based on load
    - Cloud Load Balancing reacts quickly to changes in users, traffic, backend health, network conditions, and other related conditions.  
    - gently moves traffic in fractions if backends become unhealthy.
    - only healthy backends receive reaffic
    - no pre-warming is required

different load balancer
1. <font color=red> global HTTPS load balancer </font>
   - layer 7 load balancing based on load
   - cross regional load balancing for a web application
   - route different URLs to different back ends

2. <font color=red> global SSL proxy load balancer </font>
   - layer 4 load balancing of non-HTTPS SSL traffic based on load
   - For Secure Sockets Layer traffic that is not HTTP
   - Supported on specific port numbers
   - only work for TCP and specific port numbers

3. <font color=red> global TCP proxy load balancer </font>
   - layer 4 load balancing of non-SSL TCP traffic
   - If it's other TCP traffic that does not use Secure Sockets Layer
   - Supported on specific port numbers
   - only work for TCP and specific port numbers

4. <font color=red> regional load balancer </font>
   - load balancing of any traffic (TCP/UDP) on any port number
   - load balance across a GCP region with the regional load balancer

5. <font color=red> internal load balancer </font>
   - load balance traffic inside a VPC / the project
   - for traffic coming into the Google network from the internet.
     - example:
     - between the presentation layer and the business logic layer of the application
   - accepts traffic on a GCP internal IP address and load balances it across Compute Engine VMs.
   - for the interbal tiers of multi-tier applications



![Screen Shot 2021-02-03 at 20.26.54](https://i.imgur.com/LSAsJ01.png)

---


### DNS
- 8.8.8.8
  - Google services
  - provides a public domain name service to the world.
    - DNS is what translates internet host names to addresses.
  - Google has a highly developed DNS infrastructure.
    - It makes 8.8.8.8 available so that everybody can take advantage of it.  
- Cloud DNS
  - for the internet host names and addresses of applications build in GCP
  - to help the world find them
  - a managed DNS service running on the same infrastructure as Google.
  - It has low latency and high availability
  - a cost-effective way to make the applications and services available to the users.
  - The DNS information you publish is served from redundant locations around the world.
  - Cloud DNS is also programmable.
    - publish and manage millions of DNS zones and records
    - using the GCP console, the command line interface or the API.

---


### Google Cloud CDN
- Google has a global system of edge caches.
- You can use this system to accelerate content delivery in the application
- the customers
  - experience lower network latency.
- The origins of the content
  - experience reduced load
  - and save money too.
- Once you've set up HTTPS load balancing, simply enable Cloud CDN with a single checkbox.
- CDN is a part of GCPs,
  - CDN interconnect partner program and you can continue to use it.

---

### connection

![Screen Shot 2021-02-03 at 20.38.04](https://i.imgur.com/pcVgd0Y.png)
- interconnect their networks to Google VPCs
  - such as on-premises networks or their networks in other clouds.  

- Virtual Private Network
  - Virtual Private Network connection over the internet using the IPSEC protocol.
- Cloud Router
  - To make that dynamic, they use a GCP feature called Cloud Router.
  - Cloud Router lets their networks and the Google VPC exchange route information over the VPN using the Border Gateway Protocol.
- For instance, if you add a new subnet to the Google VPC, the on-premises network will automatically get routes to it.

- Direct Peering
  - don't want to use the internet
    - either because of security concerns or need more reliable bandwidth.
  - peering with Google using Direct Peering.
  - putting a router in the same public data center as a <font color=red> Google point of presence </font> and exchanging traffic.
  - Google has more than 100 <font color=red> points of presence </font> around the world.
  - Customers who aren't already in a point of presence can contract with a partner in the carrier peering program to get connected.
  - One downside:
    - it isn't covered by a Google service level agreement.
    - Customers who want the highest uptimes for their interconnection with Google should use Dedicated Interconnect
  - If these connections have topologies that meet Google's specifications, they can be covered by up to a 99.99 percent SLA.
  - These connections can be backed up by a VPN for even greater reliability.

- Dedicated Interconnect
  - customers get one or more direct private connections to Google.
  - highest uptimes for their interconnection with Google



---


## Compute Engine

Compute Engine
- create and run virtual machines on Google infrastructure.
- no upfront investments
- run thousands of virtual CPUs on a system that is designed to be fast and to offer consistent performance.


create a virtual machine instance
- by Google Cloud Platform console or the GCloud command line tool.

- the VM can run
  - Linux and Windows Server images provided by Google or customized versions of these images
  - import images for many of the physical servers.

- pick a machine type
  - determines how much memory and virtual CPUs
  - These types range from very small to very large indeed.
  - can make a custom VM.

- processing power
  - machine learning and data processing that can take advantage of GPUs, many GCP zones have GPU's available for you.
  - Just like physical computers need disks, so do VM.

- persistent storage
  - 2 persistent storage;
    - standard or SSD.
  - If application needs high-performance scratch space,
    - attach a local SSD,
    - be sure to store data of permanent value somewhere else
    - because local SSDs content doesn't last past when the VM terminates.
  - That's why the other kinds are called persistent disks.

- choose a boot image.
  - GCP offers lots of versions of Linux and Windows
  - can import the own images too.

- want the VMs come up with certain configurations
  - like installing software packages on first boot.
  - pass <font color=red> GCP VM startup scripts </font> to do so.
  - can also pass in other kinds of metadata too.

- Once the VMs are running
  - take a durable snapshot of their disks.
  - keep these as backups or use when need to migrate a VM to another region.

- preemptible VMs 抢先的
  - have a workload that no human being is sitting around waiting to finish, say a batch job analyzing large dataset
  - benifit:
    - save money by choosing preemptible VMs to run the job.
    - although be sure to make the job able to be stopped and restarted.
  - different from an ordinary Compute Engine VM in only one respect.
    - given compute engine permission to terminate it if it's resources are needed elsewhere.  

- choose the machine properties of the instances
  - such as the number of virtual CPUs and the amount of memory
  - by using a set of predefined machine types
  - or by creating the own custom machine types.
  - the maximum number of virtual CPUs and the VM was 96 and the maximum memory size was in beta at 624 gigabytes.
  - huge VMs are great for workloads like in-memory databases and CPU intensive analytics
  - but most GCP customers start off with scaling out not scaling up.

- auto scaling
  - add and take away VMs from the application based on load metrics.

- balancing the incoming traffic across the VMs
  - Google VPC supports several different kinds of load balancing



---

## cloud storage

cloud storage is often the ingestion point for data being moved into the cloud and is frequently the long-term storage location for data.

Cloud storage can
- store App Engine logs, cloud data store backups, and objects used by App Engine applications like images.
- store instant startup scripts, Compute Engine images, and objects used by Compute Engine applications.

![Screen Shot 2021-02-03 at 23.55.15](https://i.imgur.com/q9OtPjX.png)


Google Cloud Storage
- object storage means you save to the storage here
  - you keep this arbitrary bunch of bytes I give you and the storage lets you address it with a unique key.
  - Often these unique keys are in the form of URLs which means object storage interacts nicely with Web technologies.
- a fully managed scalable service. don't need to provision capacity ahead of time.
- Just make objects and the service stores them with high durability and high availability.
- use Cloud Storage for lots of things:
  - serving website content,
  - storing data for archival and disaster recovery,
  - or distributing large data objects to the end users via Direct Download.
- Cloud Storage is:
  - not a file system because each of the objects in Cloud Storage has a URL.
  - not the same as file storage, in which you manage the data as a hierarchy of folders.
  - not the same as block storage, in which the operating system manages the data as chunks of disk.
  - would not use Cloud Storage as the root file system of the Linux box.
- Cloud Storage is
  - comprised of buckets and configure and use to hold the storage objects.

- buckets.
  - globally unique name.
  - specify a geographic location where the bucket and its contents
    - Pick a location that minimizes latency for the users.
  - and you choose a default storage class.

![Screen Shot 2021-02-03 at 22.37.13](https://i.imgur.com/lXaeAvy.png)

- <font color=red> The storage objects </font>
  - immutable,
    - do not edit them in place but instead create new versions
    - turn on object versioning on the buckets
      - Cloud Storage keeps a history of modifications.
      - it overrides or deletes all of the objects in the bucket.
      - can list the archived versions of an object,
      - restore an object to an older state
      - or permanently delete a version as needed.
    - don't turn on object versioning,
      - new always overrides old.
  - lifecycle management policies.
    - For example
    - tell Cloud Storage to delete objects older than 365 days.
    - tell it to delete objects created before January 1, 2013
    - or keep only the three most recent versions of each object in a bucket that has versioning enabled.


- Cloud Storage always encrypts the data on the server side before it is written to disk
  - you don't pay extra for that.
  - by default, data in-transit is encrypted using HTTPS.
- Once they are in Cloud Storage, you can move them onwards to other GCP storage services.

- control access to the objects and buckets.
  - Cloud IAM
  - Roles: inherited from project to bucket to object.
  - access control lists - ACLs
    - offer finer control.
    - ACLs define who has access to the buckets and objects as well as what level of access they have.
    - Each ACL consists of two pieces of information,
      - scope
        - defines who can perform the specified actions,
        - for example, a specific user or group of users
      - permission
        - defines what actions can be performed.
        - For example, read or write.




---

### storage classes:


![Screen Shot 2021-02-03 at 22.38.07](https://i.imgur.com/zQFaWOA.png)


Regional, Multi-regional, Nearline, and Coldline.  


- Multi-regional and Regional are high-performance object storage
- Nearline and Coldline are backup and archival storage.  
- All of the storage classes are accessed in comparable ways using the cloud storage API and they all offer millisecond access times.  

- Multi-regional storage `99.95 percent`
  - cost a bit more
  - but it's Geo-redundant.
  - you pick a broad geographical location like the United States, the European Union, or Asia and cloud storage stores your data in at least two geographic locations separated by at least 160 kilometers.
  - appropriate for storing frequently accessed data.
    - For example,
    - website content, interactive workloads,
    - or data that's part of mobile and gaming applications.

- Regional storage `99.9 percent Availability`
  - store data in a specific GCP region:
    - US Central one, Europe West one or Asia East one.
  - cheaper than Multi-regional storage
  - but it offers less redundancy.
  - to store data close to their Compute Engine, virtual machines, or their Kubernetes engine clusters.
    - gives better performance for data-intensive computations.

- Nearline storage `99 percent Availability`
  - low-cost, highly durable service
  - for storing infrequently accessed data.  
    - For example,
    - when plan to read or modify the data once a month or less on average.
    - continuously add files to cloud storage and access those files once a month for analysis

- <font color=red> Coldline storage </font> `99 percent Availability`
  - very low cost, highly durable service
  - for data archiving, online backup, and disaster recovery.
  - the best choice for data that you plan to access -at most- once a year.
  - due to its slightly lower availability,
  - 90-day minimum storage duration,
  - costs for data access, and higher per operation costs.
  - For example,
    - to archive data or have access to it in case of a disaster recovery event.

- pricing
  - all storage classes incur a cost per gigabyte of data stored per month
    - Multi-regional having the highest storage price
    - Coldline the lowest storage price.
  - Egress and data transfer charges may also apply.
  - Nearline storage also incurs an access fee per gigabyte of data read
  - Coldline storage incurs a higher fee per gigabyte of data read.


![Screen Shot 2021-02-03 at 23.54.12](https://i.imgur.com/suMHyqx.png)
- bring data into cloud storage.
  - use gsutil
    - the cloud storage command from this cloud SDK.
  - drag and drop in the GCP console in browser.
  - for terabytes or even petabytes of data
    - online storage transfer service
      - schedule and manage batch transfers to cloud storage from another cloud provider from a different cloud storage region or from an HTTPS endpoint.
    - offline transfer appliance
      - a rackable, high-capacity storage server that you lease from Google Cloud.
      - connect it to your network, load it with data, and then ship it to an upload facility where the data is uploaded to cloud storage.
      - securely transfer up to a petabyte of data on a single appliance.  

- other ways of getting your data into cloud storage as this storage option is tightly integrated with many of the Google cloud platform products and services.
- For example
- import and export tables from and to BigQuery as well as Cloud SQL.


---


## Database 

<img src="https://i.imgur.com/kho17mb.png" width="900">

- <font color=red> Cloud Datastore </font> `NoSQL`
  - store <font color=blue> unstructured objects </font>
  - support for `transactions`
  - support for `SQL-like queries`.
  - provides `terabytes` of capacity
  - maximum unit size of one megabyte per entity.
  - use cases:
    - best for semi-structured application data that is used in  <font color=blue> app engines' applications </font>


- <font color=red> Cloud Bigtable </font> `NoSQL`
  - store <font color=blue> large amount of structured objects </font>
  - does not support SQL's queries
  - does not support multi-row transactions.
  - provides `petabytes` of capacity
  - maximum unit size of 10 megabytes per cell and 100 megabytes per row.
  - use case
    - best for analytical data with <font color=blue> heavy read/write events </font>
    - like AdTech, Financial or IoT data.


- <font color=red> Cloud Storage </font> `Blobstore`
  - provides `petabytes` of capacity
  - maximum unit size of five terabytes per object.
  - use case:
    - best for <font color=blue> structured and unstructured, binary or object data </font>
    - store immutable blobs larger than 10 megabytes
    - such as large images, movies, large media files and backups.


- <font color=red> Cloud SQL </font> `Relational`
  - full SQL support for an online transaction processing
  - provides `terabytes` of capacity
  - use case:
    - best for <font color=blue> web frameworks and in existing applications </font>
    - like storing user credentials and customer orders.


- <font color=red> Cloud Spanner  </font> `Relational`
  - full SQL support for an online transaction processing system.
  - provides `petabytes`.
  - use case:
    - If Cloud SQL does not fit the requirements as need horizontal scalability not just through read replicas
    - best for large scale database applications that are larger than two terabytes;
    - for example, for financial trading and e-commerce use cases.


- <font color=red> BigQuery </font>
  - it sits on the edge between data storage and data processing
  - use case:
    - to use its <font color=blue> big data analysis and interactive query and capabilities </font>
  - will not use BigQuery,
    - for example, as the backings store for an online application.


---


### NoSQL database


---

#### Cloud Bigtable

> relational database
> - use tables
> - every row has the same set of columns,
> - enforced database schema:
>   - the database engine, enforces rule and other rules you specify for each table.  
> - big help for some applications but a huge pain for others.
>   - Some applications call for a much more flexible approach.
>   - example
>     - NoSQL schema.
>     - for applications that not all the rows might need to have the same columns.


Cloud Bigtable
---

- GCP fully manages the surface
  - no need to configure and tune it.

- NoSQL, big data database service.
  - databases in Bigtable are sparsely populated tables
  - can scale to billions of rows and thousands of columns
  - allowing you to store petabytes of data.

- ideal for
  - <font color=red> data that has a single lookup key </font>
    - Bigtable as a persistent hash table.
  - <font color=red> storing large amounts of data with very low latency </font>
    - supports high throughput
      - both read and write,
    - great choice for both operational and analytical applications
      - including Internet of Things, user analytics and financial data analysis.

- Cloud Bigtable is offered through the same open source API as HBase
  - HBase: the native database for the Apache Hadoop project.  
  - having the same API enables portability of applications between HBase and Bigtable.


benifits
---

- <font color=red>scalability </font>
  - compare with own Apache HBase installation,  
  - manage your own Hbase installation
    - scaling past a certain rate of queries per second is going to be tough,
  - Bigtable:
    - just increase the machine count which doesn't even require downtime.

- Cloud Bigtable <font color=red> handles administration tasks </font>
  - like upgrades and restarts transparently.

- <font color=red> encryption </font>
  - All data in Cloud Bigtable is encrypted in both in-flight and at rest.

- <font color=red> use IAM permissions </font>
  - to control who has access to Bigtable data.

- Bigtable is the same database that powers many of Google's core services
  - including search, analytics, maps and Gmail.
  - Cloud Bigtable is part of the GCP ecosystem, it can interact with other GCP services and third-party clients.



Bigtable Access Patterns
---

![Screen Shot 2021-02-04 at 00.09.22](https://i.imgur.com/HHrenvO.png)

- application API
  - data can be read from and written through data service layer
  - like Managed VMs, the HBase rest server or a Java server using the HBase client.
  - Typically, this will be to serve data to applications, dashboards and data services.

- streaming
  - Data can be streamed in through popular stream processing frameworks,
  - like Cloud Dataflow Streaming, Spark Streaming and Storm.

- batch processing
  - data can be read from and written through batch processes
  - like Hadoop map reduce, Dataflow or Spark.
  - Often, summarized or newly calculated data is written back to Cloud Bigtable or to a downstream database.


---

#### Cloud Datastore

- highly scalable NoSQL database for the applications

- main use cases
  - store structured data from App Engine apps.
  - build solutions that <font colore=blue> span App Engine and Compute Engine </font> with Cloud Datastore as the integration point.
  - fully-managed service
  - automatically handles sharding and replication,
    - providing a highly available and durable database
    - scales automatically to handle load.

- Unlike Cloud Bigtable
  - Cloud Datastore offers transactions that affect multiple database rows
  - it lets you do SQL-like queries.
  - Cloud Datastore has a free daily quota that provides storage, reads, writes, deletes and small operations at no charge.



---

### Relational database


relational database services
- use a database schema to help your application keep your data consistent and correct.
- Another feature of relational database services that helps with the same goal - transactions.
  - application can designate a group of database changes as all or nothing.
  - Either they all get made, or none do.
    - Without database transactions
    - online bank wouldn't be able to offer you the ability to move money from one account to another.
    - What if,
    - after subtracting $10,000 from one of your accounts,
    - some glitch prevented it from adding that 10,000 to the destination account?
    - Your bank would have just misplaced $10,000.


---

#### Google Cloud SQL

relational databases,
- lot of work to set up, maintain, manage, and administer.
- If that doesn't sound like a good use of your time but you still want the protections of a relational database, consider Google Cloud SQL

Google Cloud SQL
- run your own database server
  - run the database server inside a Compute Engine virtual machine,
- offers choice of the MySQL or PostgreSQL database engines
  - a fully managed service.
  - capable of handling terabytes of storage.


benefit of Cloud SQL instances
---

- <font color=red> provides several replica services </font>
  - like read, failover, and external replicas.
  - if an outage occurs, Cloud SQL can replicate data between multiple zones with automatic failover.

- <font color=red> Cloud SQL backup the data </font>
  - either on-demand or scheduled backups.

- <font color=red> It can scale both vertically and horizontally </font>
  - vertically by changing the machine type,
  - horizontally via read replicas.

- <font color=red> security perspective </font>
  - Cloud SQL instances include network firewalls,
  - and customer data is encrypted when on Google's internal networks, and when stored in database tables, temporary files, and backups.

- <font color=red> Cloud SQL instances is accessible by other GCP services and even external services. </font>
  - You can authorize `Compute Engine instances` for access `Cloud SQL instances`
  - and configure the `Cloud SQL instance` to be in the same zone as your virtual machine.

- <font color=red> Cloud SQL also supports other applications and tools </font>
  - like SQL WorkBench, Toad,
  - and other external applications using standard MySQL drivers.

![Screen Shot 2021-02-06 at 22.42.06](https://i.imgur.com/L2iJCpE.png)


---


#### Google Cloud Spanner

> If Cloud SQL does not fit your requirements because you need horizontal scaleability, Cloud Spanner.

- It offers transactional consistency at a global scale, schemas, SQL, and automatic synchronous replication for high availability.
- it can provide petabytes of capacity.

- Cloud Spanner if
  - If Cloud SQL does not fit your requirements because you need horizontal scaleability
  - you have outgrown any relational database, or sharding your databases for throughput high performance, need transactional consistency, global data and strong consistency,
  - or just want to consolidate your database.
  - Natural use cases include, financial applications, and inventory applications.

---





















.
